{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Отток клиентов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Из «Бета-Банка» стали уходить клиенты. Каждый месяц. Немного, но заметно. Банковские маркетологи посчитали: сохранять текущих клиентов дешевле, чем привлекать новых.\n",
    "\n",
    "Нужно спрогнозировать, уйдёт клиент из банка в ближайшее время или нет. Вам предоставлены исторические данные о поведении клиентов и расторжении договоров с банком. \n",
    "\n",
    "Постройте модель с предельно большим значением *F1*-меры. Чтобы сдать проект успешно, нужно довести метрику до 0.59. Проверьте *F1*-меру на тестовой выборке самостоятельно.\n",
    "\n",
    "Дополнительно измеряйте *AUC-ROC*, сравнивайте её значение с *F1*-мерой.\n",
    "\n",
    "Источник данных: [https://www.kaggle.com/barelydedicated/bank-customer-churn-modeling](https://www.kaggle.com/barelydedicated/bank-customer-churn-modeling)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import display\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, r2_score\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1.0</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8.0</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2.0</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>15574012</td>\n",
       "      <td>Chu</td>\n",
       "      <td>645</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Male</td>\n",
       "      <td>44</td>\n",
       "      <td>8.0</td>\n",
       "      <td>113755.78</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>149756.71</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>15592531</td>\n",
       "      <td>Bartlett</td>\n",
       "      <td>822</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>50</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10062.80</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>15656148</td>\n",
       "      <td>Obinna</td>\n",
       "      <td>376</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Female</td>\n",
       "      <td>29</td>\n",
       "      <td>4.0</td>\n",
       "      <td>115046.74</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>119346.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>15792365</td>\n",
       "      <td>He</td>\n",
       "      <td>501</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>44</td>\n",
       "      <td>4.0</td>\n",
       "      <td>142051.07</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>74940.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>15592389</td>\n",
       "      <td>H?</td>\n",
       "      <td>684</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>27</td>\n",
       "      <td>2.0</td>\n",
       "      <td>134603.88</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>71725.73</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
       "0          1    15634602  Hargrave          619    France  Female   42   \n",
       "1          2    15647311      Hill          608     Spain  Female   41   \n",
       "2          3    15619304      Onio          502    France  Female   42   \n",
       "3          4    15701354      Boni          699    France  Female   39   \n",
       "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
       "5          6    15574012       Chu          645     Spain    Male   44   \n",
       "6          7    15592531  Bartlett          822    France    Male   50   \n",
       "7          8    15656148    Obinna          376   Germany  Female   29   \n",
       "8          9    15792365        He          501    France    Male   44   \n",
       "9         10    15592389        H?          684    France    Male   27   \n",
       "\n",
       "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0     2.0       0.00              1          1               1   \n",
       "1     1.0   83807.86              1          0               1   \n",
       "2     8.0  159660.80              3          1               0   \n",
       "3     1.0       0.00              2          0               0   \n",
       "4     2.0  125510.82              1          1               1   \n",
       "5     8.0  113755.78              2          1               0   \n",
       "6     7.0       0.00              2          1               1   \n",
       "7     4.0  115046.74              4          1               0   \n",
       "8     4.0  142051.07              2          0               1   \n",
       "9     2.0  134603.88              1          1               1   \n",
       "\n",
       "   EstimatedSalary  Exited  \n",
       "0        101348.88       1  \n",
       "1        112542.58       0  \n",
       "2        113931.57       1  \n",
       "3         93826.63       0  \n",
       "4         79084.10       0  \n",
       "5        149756.71       1  \n",
       "6         10062.80       0  \n",
       "7        119346.88       1  \n",
       "8         74940.50       0  \n",
       "9         71725.73       0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 14 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   RowNumber        10000 non-null  int64  \n",
      " 1   CustomerId       10000 non-null  int64  \n",
      " 2   Surname          10000 non-null  object \n",
      " 3   CreditScore      10000 non-null  int64  \n",
      " 4   Geography        10000 non-null  object \n",
      " 5   Gender           10000 non-null  object \n",
      " 6   Age              10000 non-null  int64  \n",
      " 7   Tenure           9091 non-null   float64\n",
      " 8   Balance          10000 non-null  float64\n",
      " 9   NumOfProducts    10000 non-null  int64  \n",
      " 10  HasCrCard        10000 non-null  int64  \n",
      " 11  IsActiveMember   10000 non-null  int64  \n",
      " 12  EstimatedSalary  10000 non-null  float64\n",
      " 13  Exited           10000 non-null  int64  \n",
      "dtypes: float64(3), int64(8), object(3)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('/datasets/Churn.csv')\n",
    "\n",
    "display(data.head(10))\n",
    "\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RowNumber          0.0000\n",
       "CustomerId         0.0000\n",
       "Surname            0.0000\n",
       "CreditScore        0.0000\n",
       "Geography          0.0000\n",
       "Gender             0.0000\n",
       "Age                0.0000\n",
       "Tenure             0.0909\n",
       "Balance            0.0000\n",
       "NumOfProducts      0.0000\n",
       "HasCrCard          0.0000\n",
       "IsActiveMember     0.0000\n",
       "EstimatedSalary    0.0000\n",
       "Exited             0.0000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Gender                 2\n",
       "HasCrCard              2\n",
       "IsActiveMember         2\n",
       "Exited                 2\n",
       "Geography              3\n",
       "NumOfProducts          4\n",
       "Tenure                11\n",
       "Age                   70\n",
       "CreditScore          460\n",
       "Surname             2932\n",
       "Balance             6382\n",
       "EstimatedSalary     9999\n",
       "RowNumber          10000\n",
       "CustomerId         10000\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.nunique().sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пропуски в колонке Tenure. Они составляют 9%.\n",
    "Дубликатов и повтораяющихся значений нет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Удалим столбцы CustomerId, RowNumber, Surname - так как для обучения модели они не пригодятся\n",
    "data = data.drop(['CustomerId', 'RowNumber', 'Surname'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Exited_x</th>\n",
       "      <th>Exited_y</th>\n",
       "      <th>ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>217</td>\n",
       "      <td>2261</td>\n",
       "      <td>0.095975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>247</td>\n",
       "      <td>2753</td>\n",
       "      <td>0.089720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Germany</td>\n",
       "      <td>Female</td>\n",
       "      <td>108</td>\n",
       "      <td>1193</td>\n",
       "      <td>0.090528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Germany</td>\n",
       "      <td>Male</td>\n",
       "      <td>108</td>\n",
       "      <td>1316</td>\n",
       "      <td>0.082067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>101</td>\n",
       "      <td>1089</td>\n",
       "      <td>0.092746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Spain</td>\n",
       "      <td>Male</td>\n",
       "      <td>128</td>\n",
       "      <td>1388</td>\n",
       "      <td>0.092219</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Geography  Gender  Exited_x  Exited_y     ratio\n",
       "0    France  Female       217      2261  0.095975\n",
       "1    France    Male       247      2753  0.089720\n",
       "2   Germany  Female       108      1193  0.090528\n",
       "3   Germany    Male       108      1316  0.082067\n",
       "4     Spain  Female       101      1089  0.092746\n",
       "5     Spain    Male       128      1388  0.092219"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Посмотрим, как распределены пропуски в данных между клиентами из разных стран по половому признаку\n",
    "\n",
    "t_nans = data[data['Tenure'].isna()].groupby(['Geography', 'Gender'])['Exited'].count().reset_index()\n",
    "t_all = data.groupby(['Geography', 'Gender'])['Exited'].count().reset_index()\n",
    "t = pd.merge(t_nans, t_all, on=['Geography', 'Gender'])\n",
    "t['ratio'] = t['Exited_x'] / t['Exited_y']\n",
    "display(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пропуски распределены равномерно (примерно в одинаковом соотношении) по группам."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2037"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Exited'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.20132013201320131"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data['Tenure'].isna()]['Exited'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Баланс классов у пропусков примерно такой же как в датасете."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>9091.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.00000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>650.528800</td>\n",
       "      <td>38.921800</td>\n",
       "      <td>4.997690</td>\n",
       "      <td>76485.889288</td>\n",
       "      <td>1.530200</td>\n",
       "      <td>0.70550</td>\n",
       "      <td>0.515100</td>\n",
       "      <td>100090.239881</td>\n",
       "      <td>0.203700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>96.653299</td>\n",
       "      <td>10.487806</td>\n",
       "      <td>2.894723</td>\n",
       "      <td>62397.405202</td>\n",
       "      <td>0.581654</td>\n",
       "      <td>0.45584</td>\n",
       "      <td>0.499797</td>\n",
       "      <td>57510.492818</td>\n",
       "      <td>0.402769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>350.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.580000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>584.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>51002.110000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>652.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>97198.540000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>100193.915000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>718.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>127644.240000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>149388.247500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>850.000000</td>\n",
       "      <td>92.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>250898.090000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>199992.480000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        CreditScore           Age       Tenure        Balance  NumOfProducts  \\\n",
       "count  10000.000000  10000.000000  9091.000000   10000.000000   10000.000000   \n",
       "mean     650.528800     38.921800     4.997690   76485.889288       1.530200   \n",
       "std       96.653299     10.487806     2.894723   62397.405202       0.581654   \n",
       "min      350.000000     18.000000     0.000000       0.000000       1.000000   \n",
       "25%      584.000000     32.000000     2.000000       0.000000       1.000000   \n",
       "50%      652.000000     37.000000     5.000000   97198.540000       1.000000   \n",
       "75%      718.000000     44.000000     7.000000  127644.240000       2.000000   \n",
       "max      850.000000     92.000000    10.000000  250898.090000       4.000000   \n",
       "\n",
       "         HasCrCard  IsActiveMember  EstimatedSalary        Exited  \n",
       "count  10000.00000    10000.000000     10000.000000  10000.000000  \n",
       "mean       0.70550        0.515100    100090.239881      0.203700  \n",
       "std        0.45584        0.499797     57510.492818      0.402769  \n",
       "min        0.00000        0.000000        11.580000      0.000000  \n",
       "25%        0.00000        0.000000     51002.110000      0.000000  \n",
       "50%        1.00000        1.000000    100193.915000      0.000000  \n",
       "75%        1.00000        1.000000    149388.247500      0.000000  \n",
       "max        1.00000        1.000000    199992.480000      1.000000  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Определим категориальные и численные переменные\n",
    "\n",
    "cat_columns = ['Gender',\n",
    "               'HasCrCard',\n",
    "               'IsActiveMember',\n",
    "               'Geography',\n",
    "               'NumOfProducts',\n",
    "               'Tenure'\n",
    "]\n",
    "\n",
    "num_columns = ['Age',\n",
    "               'CreditScore',\n",
    "               'Balance',\n",
    "               'EstimatedSalary',\n",
    "]\n",
    "\n",
    "\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- В столбце Tenure есть пропущенные данные: данные могли отсутствовать изначально или быть утеряны из-за сбоев в системе при выгрузке базы.\n",
    "\n",
    "- Попробуем построить модель, предсказывающую данный параметр на основе имеющихся данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# сохраним данные с пропущенными значениями 'Tenure' в отдельной переменной\n",
    "no_tenure_df = data.loc[data['Tenure'].isna()]\n",
    "features = data.loc[~data['Tenure'].isna()]\n",
    "\n",
    "# основной целевой признак 'Exited' не будет участвовать в данной модели\n",
    "features = features.drop('Exited', axis=1)\n",
    "\n",
    "# в данной модели признак 'Tenure' выступает в качестве целевого\n",
    "y = features['Tenure']\n",
    "X = features.drop('Tenure', axis=1)\n",
    "X = features[['EstimatedSalary', 'Age', 'CreditScore']]\n",
    "\n",
    "# разделим данные на обучающую и валидационную выборки\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.25, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Классификацию попробуем провести с помощью модели \"Случайный Лес\". \n",
    "#Так как признак 'Tenure' распределён равномерно между 11 значениями, попробуем оценивать качество модели с помощью accuracy.\n",
    "#в параметрах best_params и best_accuracy будем хранить наилучшие параметры для модели и наивысшую точность соответственно\n",
    "best_params = []\n",
    "best_accuracy = 0\n",
    "# проходим в циклах по всем выбранным гиперпараметрам\n",
    "for n_estimators in (1,10):\n",
    "    for max_depth in range(2,10):\n",
    "        for min_samples_split in range(2,10):\n",
    "            for min_samples_leaf in range(1,8):\n",
    "                for criterion in ['gini', 'entropy']:\n",
    "                    # инициация модели с текущими гиперпараметрами\n",
    "                    model_forest = RandomForestClassifier(random_state=123,\n",
    "                                                          n_estimators=n_estimators,\n",
    "                                                          max_depth=max_depth,\n",
    "                                                          min_samples_split=min_samples_split,\n",
    "                                                          min_samples_leaf=min_samples_leaf,\n",
    "                                                          criterion=criterion)\n",
    "                    # обучение модели на тренировочной выборке\n",
    "                    model_forest.fit(X_train, y_train)\n",
    "                    # поиск предсказаний модели на валидационной выбоке\n",
    "                    predictions = model_forest.predict(X_valid)\n",
    "                    # вычисление точности модели методом accuracy_score\n",
    "                    accuracy = accuracy_score(y_valid, predictions)\n",
    "                    # если текущее значение точности выше предыдущего лучшего значения, \n",
    "                    # сохраняем параметры модели и текущую точность\n",
    "                    if accuracy > best_accuracy:\n",
    "                        best_params = [n_estimators, max_depth, min_samples_split, min_samples_leaf, criterion]\n",
    "                        best_accuracy = accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Наилучшая точность: 0.12\n",
      "Параметры модели:\n",
      "   n_estimators = 10\n",
      "   max_depth = 5\n",
      "   min_samples_split = 2\n",
      "   min_samples_leaf = 2\n",
      "   criterion = entropy \n"
     ]
    }
   ],
   "source": [
    "# вывод наилучшей точности и параметров модели.\n",
    "print('''Наилучшая точность: {}\n",
    "Параметры модели:\n",
    "   n_estimators = {}\n",
    "   max_depth = {}\n",
    "   min_samples_split = {}\n",
    "   min_samples_leaf = {}\n",
    "   criterion = {} '''.format(round(best_accuracy, 2),\n",
    "                             best_params[0],\n",
    "                             best_params[1],\n",
    "                             best_params[2],\n",
    "                             best_params[3],\n",
    "                             best_params[4]\n",
    "                            ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy модели 12% слишком мал (случайный выбор между 11 классами даст около 9%). Другие модели классификации не улучшили качество классификации.\n",
    "\n",
    "Регрессионные модели (представление Tenure количественным признаком) не дали положительного результата (r2 близок к 0 для LinearRegression и RandomForestRegressor).\n",
    "\n",
    "В данном случае представим признак Tenure категориальным, преобразуем его методом One-Hot Encoding, пропущенные значения будут отдельной категорией."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 22 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   CreditScore        10000 non-null  int64  \n",
      " 1   Age                10000 non-null  int64  \n",
      " 2   Balance            10000 non-null  float64\n",
      " 3   NumOfProducts      10000 non-null  int64  \n",
      " 4   HasCrCard          10000 non-null  int64  \n",
      " 5   IsActiveMember     10000 non-null  int64  \n",
      " 6   EstimatedSalary    10000 non-null  float64\n",
      " 7   Exited             10000 non-null  int64  \n",
      " 8   Geography_Germany  10000 non-null  uint8  \n",
      " 9   Geography_Spain    10000 non-null  uint8  \n",
      " 10  Gender_Male        10000 non-null  uint8  \n",
      " 11  Tenure_0.0         10000 non-null  uint8  \n",
      " 12  Tenure_1.0         10000 non-null  uint8  \n",
      " 13  Tenure_2.0         10000 non-null  uint8  \n",
      " 14  Tenure_3.0         10000 non-null  uint8  \n",
      " 15  Tenure_4.0         10000 non-null  uint8  \n",
      " 16  Tenure_5.0         10000 non-null  uint8  \n",
      " 17  Tenure_6.0         10000 non-null  uint8  \n",
      " 18  Tenure_7.0         10000 non-null  uint8  \n",
      " 19  Tenure_8.0         10000 non-null  uint8  \n",
      " 20  Tenure_9.0         10000 non-null  uint8  \n",
      " 21  Tenure_10.0        10000 non-null  uint8  \n",
      "dtypes: float64(2), int64(6), uint8(14)\n",
      "memory usage: 761.8 KB\n"
     ]
    }
   ],
   "source": [
    "data.loc[data['Tenure'].isna(), 'Tenure'] = -1\n",
    "data['Tenure'] = data['Tenure'].astype('object')\n",
    "data = pd.get_dummies(data, drop_first=True)\n",
    "\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Age</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "      <th>Geography_Germany</th>\n",
       "      <th>Geography_Spain</th>\n",
       "      <th>...</th>\n",
       "      <th>Tenure_1.0</th>\n",
       "      <th>Tenure_2.0</th>\n",
       "      <th>Tenure_3.0</th>\n",
       "      <th>Tenure_4.0</th>\n",
       "      <th>Tenure_5.0</th>\n",
       "      <th>Tenure_6.0</th>\n",
       "      <th>Tenure_7.0</th>\n",
       "      <th>Tenure_8.0</th>\n",
       "      <th>Tenure_9.0</th>\n",
       "      <th>Tenure_10.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>42</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>41</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>42</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>39</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>43</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>645</td>\n",
       "      <td>44</td>\n",
       "      <td>113755.78</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>149756.71</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>822</td>\n",
       "      <td>50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10062.80</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>376</td>\n",
       "      <td>29</td>\n",
       "      <td>115046.74</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>119346.88</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>501</td>\n",
       "      <td>44</td>\n",
       "      <td>142051.07</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>74940.50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>684</td>\n",
       "      <td>27</td>\n",
       "      <td>134603.88</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>71725.73</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   CreditScore  Age    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0          619   42       0.00              1          1               1   \n",
       "1          608   41   83807.86              1          0               1   \n",
       "2          502   42  159660.80              3          1               0   \n",
       "3          699   39       0.00              2          0               0   \n",
       "4          850   43  125510.82              1          1               1   \n",
       "5          645   44  113755.78              2          1               0   \n",
       "6          822   50       0.00              2          1               1   \n",
       "7          376   29  115046.74              4          1               0   \n",
       "8          501   44  142051.07              2          0               1   \n",
       "9          684   27  134603.88              1          1               1   \n",
       "\n",
       "   EstimatedSalary  Exited  Geography_Germany  Geography_Spain  ...  \\\n",
       "0        101348.88       1                  0                0  ...   \n",
       "1        112542.58       0                  0                1  ...   \n",
       "2        113931.57       1                  0                0  ...   \n",
       "3         93826.63       0                  0                0  ...   \n",
       "4         79084.10       0                  0                1  ...   \n",
       "5        149756.71       1                  0                1  ...   \n",
       "6         10062.80       0                  0                0  ...   \n",
       "7        119346.88       1                  1                0  ...   \n",
       "8         74940.50       0                  0                0  ...   \n",
       "9         71725.73       0                  0                0  ...   \n",
       "\n",
       "   Tenure_1.0  Tenure_2.0  Tenure_3.0  Tenure_4.0  Tenure_5.0  Tenure_6.0  \\\n",
       "0           0           1           0           0           0           0   \n",
       "1           1           0           0           0           0           0   \n",
       "2           0           0           0           0           0           0   \n",
       "3           1           0           0           0           0           0   \n",
       "4           0           1           0           0           0           0   \n",
       "5           0           0           0           0           0           0   \n",
       "6           0           0           0           0           0           0   \n",
       "7           0           0           0           1           0           0   \n",
       "8           0           0           0           1           0           0   \n",
       "9           0           1           0           0           0           0   \n",
       "\n",
       "   Tenure_7.0  Tenure_8.0  Tenure_9.0  Tenure_10.0  \n",
       "0           0           0           0            0  \n",
       "1           0           0           0            0  \n",
       "2           0           1           0            0  \n",
       "3           0           0           0            0  \n",
       "4           0           0           0            0  \n",
       "5           0           1           0            0  \n",
       "6           1           0           0            0  \n",
       "7           0           0           0            0  \n",
       "8           0           0           0            0  \n",
       "9           0           0           0            0  \n",
       "\n",
       "[10 rows x 22 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(data.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Данные успешно загружены и проверены на соответствие описанию. Дубликатов нет. Типы данных преобразованы в соответствии с хранимой информацией\n",
    "- Признаки RowNumber, CustomerId и Surname удалены, так как целевой признак от них никак не зависит.\n",
    "- В признаке Tenure обнаружено 9% пропусков. Попытка построить классификационную модель для заполнения пропусков не принесла существенных результатов (качество модели 12%, при случайном заполнении 9%). Данный признак преобразован прямым кодированием One-Hot Encoder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Исследование задачи"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Подготовка**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_valid, test = train_test_split(data, test_size=0.2, random_state=1234)\n",
    "train, valid = train_test_split(train_valid, test_size=0.25, random_state=1234)\n",
    "\n",
    "features_train = train.drop(['Exited'], axis=1)\n",
    "target_train = train['Exited']\n",
    "features_valid = valid.drop(['Exited'], axis=1)\n",
    "target_valid = valid['Exited']\n",
    "features_test = test.drop(['Exited'], axis=1)\n",
    "target_test = test['Exited']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Попробуем обучить различные классификационные модели без учёта дисбаланса классов**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***РЕШАЮЩЕЕ ДЕРЕВО***\n",
    "\n",
    "Инициируем модель решающего дерева DecisionTreeClassifier<br>\n",
    "\n",
    "Выделим гиперпараметры для настройки модели:<br>\n",
    "- max_depth - максимальная глубина древа<br>\n",
    "- min_samples_split - минимальное количество объектов в узле<br>\n",
    "- min_samples_leaf - минимальное количество объектов в листе<br>\n",
    "- criterion (\"gini\" или \"entropy\") - функция измерения качества разделения<br>\n",
    "\n",
    "Критерием проверки качества модели будет f1 и roc_auc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Наилучшая метрика f1: 0.557\n",
      "    Парамтеры модели:\n",
      "       max_depth = 8\n",
      "       min_samples_split = 2\n",
      "       min_samples_leaf = 1\n",
      "       criterion = entropy \n",
      "\n",
      "Наилучшая метрика roc_auc: 0.83\n",
      "    Парамтеры модели:\n",
      "       max_depth = 7\n",
      "       min_samples_split = 2\n",
      "       min_samples_leaf = 8\n",
      "       criterion = gini \n"
     ]
    }
   ],
   "source": [
    "def decision_tree(features_train, features_valid, target_train, target_valid, cw=None):\n",
    "    # в параметрах best_params_f1 и best_f1 будем хранить наилучшие параметры для модели и наивысшую f1 метрику соответственно\n",
    "    best_params_f1 = []\n",
    "    best_f1 = 0\n",
    "    # аналогично для roc_auc метрики.\n",
    "    best_params_roc_auc = []\n",
    "    best_roc_auc = 0.5\n",
    "    # проходим в циклах по всем выбранным гиперпараметрам\n",
    "    for max_depth in range(2,10):\n",
    "        for min_samples_split in range(2,6):\n",
    "            for min_samples_leaf in range(1,10):\n",
    "                for criterion in ['gini', 'entropy']:\n",
    "                    # инициация модели с текущими гиперпараметрами\n",
    "                    model_tree = DecisionTreeClassifier(random_state=123, max_depth=max_depth,\n",
    "                                                        min_samples_split=min_samples_split,\n",
    "                                                        min_samples_leaf=min_samples_leaf,\n",
    "                                                        criterion=criterion, class_weight=cw)\n",
    "                    # обучение модели на тренировочной выборке\n",
    "                    model_tree.fit(features_train, target_train)\n",
    "                    # поиск предсказаний модели на валидационной выбоке\n",
    "                    predictions = model_tree.predict(features_valid)\n",
    "                    # вычисление f1 модели методом f1_score\n",
    "                    f1 = f1_score(target_valid, predictions)\n",
    "                    # если текущее значение метрики f1 выше предыдущего лучшего значения, \n",
    "                    # сохраняем параметры модели и текущую метрику f1\n",
    "                    if f1 > best_f1:\n",
    "                        best_params_f1 = [max_depth, min_samples_split, min_samples_leaf, criterion]\n",
    "                        best_f1 = f1\n",
    "                    # аналогично для метрики roc_auc\n",
    "                    roc_auc = roc_auc_score(target_valid, model_tree.predict_proba(features_valid)[:,1]) #КОД РЕВЬЮЕРА\n",
    "                    if roc_auc > best_roc_auc:\n",
    "                        best_params_roc_auc = [max_depth, min_samples_split, min_samples_leaf, criterion]\n",
    "                        best_roc_auc = roc_auc\n",
    "    # вывод наилучшей метрики f1 и параметров модели.\n",
    "    print('''Наилучшая метрика f1: {}\n",
    "    Парамтеры модели:\n",
    "       max_depth = {}\n",
    "       min_samples_split = {}\n",
    "       min_samples_leaf = {}\n",
    "       criterion = {} \\n'''.format(round(best_f1, 3),\n",
    "                                 best_params_f1[0],\n",
    "                                 best_params_f1[1],\n",
    "                                 best_params_f1[2],\n",
    "                                 best_params_f1[3]\n",
    "                                ))\n",
    "    # вывод наилучшей метрики roc_auc и параметров модели.\n",
    "    print('''Наилучшая метрика roc_auc: {}\n",
    "    Парамтеры модели:\n",
    "       max_depth = {}\n",
    "       min_samples_split = {}\n",
    "       min_samples_leaf = {}\n",
    "       criterion = {} '''.format(round(best_roc_auc, 3),\n",
    "                                 best_params_roc_auc[0],\n",
    "                                 best_params_roc_auc[1],\n",
    "                                 best_params_roc_auc[2],\n",
    "                                 best_params_roc_auc[3]\n",
    "                                ))\n",
    "    \n",
    "decision_tree(features_train, features_valid, target_train, target_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Наилучшая метрика f1 для решающего дерева 0.557 (не достаточно по техническому заданию).\n",
    "- Наилучший результат по метрикам f1 и roc_auc достигается при одинаковой настройке гиперпараметров.\n",
    "\n",
    "Попробуем улучшить результат на других моделях"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***СЛУЧАЙНЫЙ ЛЕС***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Инициируем модель случайного леса RandomForestClassifierm<br>\n",
    "\n",
    "Выделим гиперпараметры для настройки модели:<br>\n",
    "- n_estimators - количество деревьев\n",
    "- max_depth - максимальная глубина древа\n",
    "- min_samples_split - минимальное количество объектов в узле\n",
    "- min_samples_leaf - минимальное количество объектов в листе\n",
    "\n",
    "Критерием проверки качества модели будет f1 и roc_auc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Наилучшая метрика f1: 0.586\n",
      "    Парамтеры модели:\n",
      "       n_estimators = 30\n",
      "       max_depth = 14\n",
      "       min_samples_split = 2\n",
      "       min_samples_leaf = 2 \n",
      "\n",
      "Наилучшая метрика roc_auc: 0.859\n",
      "    Парамтеры модели:\n",
      "       n_estimators = 39\n",
      "       max_depth = 16\n",
      "       min_samples_split = 2\n",
      "       min_samples_leaf = 2 \n"
     ]
    }
   ],
   "source": [
    "def random_forest(features_train, features_valid, target_train, target_valid, cw=None):\n",
    "    # в параметрах best_params_f1 и best_f1 будем хранить наилучшие параметры для модели и наивысшую f1 метрику соответственно\n",
    "    best_params_f1 = []\n",
    "    best_f1 = 0\n",
    "    # аналогично для roc_auc метрики.\n",
    "    best_params_roc_auc = []\n",
    "    best_roc_auc = 0.5\n",
    "    # проходим в циклах по всем выбранным гиперпараметрам\n",
    "    for n_estimators in range(30,40):\n",
    "        for max_depth in range(10,17,2):\n",
    "            for min_samples_split in range(2,5):\n",
    "                for min_samples_leaf in range(1,4):\n",
    "                    # инициация модели с текущими гиперпараметрами\n",
    "                    model_forest = RandomForestClassifier(random_state=123,\n",
    "                                                          n_estimators=n_estimators,\n",
    "                                                          max_depth=max_depth,\n",
    "                                                          min_samples_split=min_samples_split,\n",
    "                                                          min_samples_leaf=min_samples_leaf)\n",
    "                    # обучение модели на тренировочной выборке\n",
    "                    model_forest.fit(features_train, target_train)\n",
    "                    # поиск предсказаний модели на валидационной выбоке\n",
    "                    predictions = model_forest.predict(features_valid)\n",
    "\n",
    "                    # вычисление f1 модели методом f1_score\n",
    "                    f1 = f1_score(target_valid, predictions)\n",
    "                    # если текущее значение метрики f1 выше предыдущего лучшего значения, \n",
    "                    # сохраняем параметры модели и текущую метрику f1\n",
    "                    if f1 > best_f1:\n",
    "                        best_params_f1 = [n_estimators, max_depth, min_samples_split, min_samples_leaf]\n",
    "                        best_f1 = f1\n",
    "                    # аналогично для метрики roc_auc\n",
    "                    roc_auc = roc_auc = roc_auc_score(target_valid, model_forest.predict_proba(features_valid)[:,1])\n",
    "                    if roc_auc > best_roc_auc:\n",
    "                        best_params_roc_auc = [n_estimators, max_depth, min_samples_split, min_samples_leaf]\n",
    "                        best_roc_auc = roc_auc\n",
    "\n",
    "    # вывод наилучшей метрики f1 и параметров модели.\n",
    "    print('''Наилучшая метрика f1: {}\n",
    "    Парамтеры модели:\n",
    "       n_estimators = {}\n",
    "       max_depth = {}\n",
    "       min_samples_split = {}\n",
    "       min_samples_leaf = {} \\n'''.format(round(best_f1, 3),\n",
    "                                 best_params_f1[0],\n",
    "                                 best_params_f1[1],\n",
    "                                 best_params_f1[2],\n",
    "                                 best_params_f1[3]\n",
    "                                ))\n",
    "\n",
    "    # вывод наилучшей метрики roc_auc и параметров модели.\n",
    "    print('''Наилучшая метрика roc_auc: {}\n",
    "    Парамтеры модели:\n",
    "       n_estimators = {}\n",
    "       max_depth = {}\n",
    "       min_samples_split = {}\n",
    "       min_samples_leaf = {} '''.format(round(best_roc_auc, 3),\n",
    "                                        best_params_roc_auc[0],\n",
    "                                        best_params_roc_auc[1],\n",
    "                                        best_params_roc_auc[2],\n",
    "                                        best_params_roc_auc[3]\n",
    "                                       ))\n",
    "random_forest(features_train, features_valid, target_train, target_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Наилучшая метрика f1 для случайного леса 0.586 (не достаточно по техническому заданию).\n",
    "- Наилучший результат по метрикам f1 и roc_auc достигается при одинаковой настройке гиперпараметров.\n",
    "\n",
    "Попробуем улучшить результат на других моделях."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***ЛОГИСТИЧЕСКАЯ РЕГРЕССИЯ***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Инициируем модель случайного леса RandomForestClassifierm<br>\n",
    "\n",
    "Выделим гиперпараметры для настройки модели:<br>\n",
    "- С - инверсия силы регуляризации\n",
    "\n",
    "Критерием проверки качества модели будет f1 и roc_auc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# в параметрах best_params_f1 и best_f1 будем хранить наилучшие параметры для модели и наивысшую f1 метрику соответственно\n",
    "best_params_f1 = []\n",
    "best_f1 = 0\n",
    "# аналогично для roc_auc метрики.\n",
    "best_params_roc_auc = []\n",
    "best_roc_auc = 0.5\n",
    "\n",
    "#cs = np.linspace(0.01, 100, 1000, endpoint=True)\n",
    "cs = range(1, 100)\n",
    "# проходим в циклах по всем выбранным гиперпараметрам\n",
    "for C in cs:\n",
    "    # инициация модели с текущими гиперпараметрами\n",
    "    model_regression = LogisticRegression(random_state=123,\n",
    "                                      C=C,\n",
    "                                      max_iter=1000)\n",
    "    # обучение модели на тренировочной выборке\n",
    "    model_regression.fit(features_train, target_train)\n",
    "    # поиск предсказаний модели на валидационной выбоке\n",
    "    predictions = model_regression.predict(features_valid)\n",
    "\n",
    "    # вычисление f1 модели методом f1_score\n",
    "    f1 = f1_score(target_valid, predictions)\n",
    "    # если текущее значение метрики f1 выше предыдущего лучшего значения, \n",
    "    # сохраняем параметры модели и текущую метрику f1\n",
    "    if f1 > best_f1:\n",
    "        best_params_f1 = [C]\n",
    "        best_f1 = f1\n",
    "    # аналогично для метрики roc_auc\n",
    "    roc_auc = roc_auc_score(target_valid, model_regression.predict_proba(features_valid)[:,1])\n",
    "    if roc_auc > best_roc_auc:\n",
    "        best_params_roc_auc = [C]\n",
    "        best_roc_auc = roc_auc       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Наилучшая метрика f1: 0.1\n",
      "Парамтеры модели:\n",
      "   C = 1 \n",
      "Наилучшая метрика roc_auc: 0.658\n",
      "Парамтеры модели:\n",
      "   C = 1 \n"
     ]
    }
   ],
   "source": [
    "# вывод наилучшей метрики f1 и параметров модели.\n",
    "print('''Наилучшая метрика f1: {}\n",
    "Парамтеры модели:\n",
    "   C = {} '''.format(round(best_f1, 3),\n",
    "                             best_params_f1[0]\n",
    "                            ))\n",
    "\n",
    "# вывод наилучшей метрики roc_auc и параметров модели.\n",
    "print('''Наилучшая метрика roc_auc: {}\n",
    "Парамтеры модели:\n",
    "   C = {} '''.format(round(best_roc_auc, 3),\n",
    "                             best_params_roc_auc[0]\n",
    "                            ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Наилучшая метрика f1 для логистической регрессии 0.108 (хуже, чем на остальных моделях).\n",
    "- Наилучший результат по метрикам f1 и roc_auc достигается при одинаковой настройке гиперпараметров.\n",
    "\n",
    "Попробуем улучшить результат, разобравшись с дисбалансом классов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Выводы**\n",
    "- Исходные данные разделены на обучающую, валидационную и тестовую выборки в соотношении 60/20/20 соответственно\n",
    "- Обучены модели \"Решающее Дерево\", \"Случайный лес\", \"Логистическая Регрессия\" без учёта дисбаланса классов. Максимальное значение метрики f1 = 0.586 получено при обучении модели случайного леса. Качество модели не удовлетворяет условию технического задания.\n",
    "- Качество моделей также оценено по метрике roc_auc. Максимальное значение метрики roc_auc = 0.859 достигнуто при обучении модели случайного леса.\n",
    "- Метрики f1 и roc_auc достигли максимальных значений при одинаковых настройках гиперпараметров (но такой результат получается не всегда)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Борьба с дисбалансом"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для борьбы с дисбалансом классов попробуем:\n",
    "- взвешивание классов (class_weight='balanced')\n",
    "- увеличение выборки положительного класса (копирование объектов)\n",
    "- уменьшение выборки отрицательного класса (sampling)\n",
    "- перемешивание объектов методом shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Взвешивание классов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Наилучшая метрика f1: 0.59\n",
      "    Парамтеры модели:\n",
      "       max_depth = 9\n",
      "       min_samples_split = 2\n",
      "       min_samples_leaf = 7\n",
      "       criterion = gini \n",
      "\n",
      "Наилучшая метрика roc_auc: 0.833\n",
      "    Парамтеры модели:\n",
      "       max_depth = 7\n",
      "       min_samples_split = 2\n",
      "       min_samples_leaf = 7\n",
      "       criterion = entropy \n"
     ]
    }
   ],
   "source": [
    "decision_tree(features_train, features_valid, target_train, target_valid, cw='balanced')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Взвешивание классов почти не дало прироста в метрике f1 на решающем дереве.<br>\n",
    "Отметим, что в данном случае наилучшие значения метрик f1 и roc_auc достигаются при различных настройках гиперпараметров.<br>\n",
    "Применим upsampling и downsampling. Проверим результаты на модели случайного леса (она дала наилучший результат при начальном исследовании)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upsampling и downsampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Напишем функции для увеличения и уменьшения выборок."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upsample(features, target, repeat):\n",
    "    \"\"\"\n",
    "    input:        features - признаки \n",
    "                  target - целевой признак\n",
    "                  repeat (int) - множитель для повторения признаков\n",
    "    output:       features_upsampled - увеличенная выборка признаков\n",
    "                  target_upsampled - увеличенная выборка целевого признака\n",
    "    description:  функция разделяет признаки по классам целевого признака (0, 1),\n",
    "                  повторяет признаки целевого положительного класса repeat раз,\n",
    "                  объединяет объекты с разными целевыми признаками методом concat,\n",
    "                  перемешивает объекты методом shuffle\n",
    "    \"\"\"\n",
    "    features_zeros = features[target == 0]\n",
    "    features_ones = features[target == 1]\n",
    "    target_zeros = target[target == 0]\n",
    "    target_ones = target[target == 1]\n",
    "    \n",
    "    features_upsampled = pd.concat([features_zeros] + [features_ones] * repeat)\n",
    "    target_upsampled = pd.concat([target_zeros] + [target_ones] * repeat)\n",
    "    \n",
    "    features_upsampled, target_upsampled = shuffle(\n",
    "        features_upsampled, target_upsampled, random_state=12345)\n",
    "    return features_upsampled, target_upsampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downsample(features, target, fraction):\n",
    "    \"\"\"\n",
    "    input:        features - признаки \n",
    "                  target - целево признак\n",
    "                  fraction (float) - доля объектов для сэмплирования\n",
    "    output:       features_downsampled - уменьшенная выборка признаков\n",
    "                  target_downsampled - уменьшенная выборка целевого признака\n",
    "    description:  функция разделяет признаки по классам целевого признака (0, 1), \n",
    "                  сэмплирует признаки целевого класса 0 (с коэффициентом fraction),\n",
    "                  объединяет объекты с разными целевыми признаками методом concat,\n",
    "                  перемешивает объекты методом shuffle\n",
    "    \"\"\"\n",
    "    features_zeros = features[target == 0]\n",
    "    features_ones = features[target == 1]\n",
    "    target_zeros = target[target == 0]\n",
    "    target_ones = target[target == 1]\n",
    "    \n",
    "    features_downsampled = pd.concat(\n",
    "        [features_zeros.sample(frac=fraction, random_state=12345)] + [features_ones])\n",
    "    target_downsampled = pd.concat(\n",
    "        [target_zeros.sample(frac=fraction, random_state=12345)] + [target_ones])\n",
    "    \n",
    "    features_downsampled, target_downsampled = shuffle(\n",
    "        features_downsampled, target_downsampled, random_state=12345)\n",
    "    return features_downsampled, target_downsampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Для обучающей выборки увеличим количество объектов класса 1 в 2 раза, уменьшим количество объектов класса 0 в 1.5 раза.\n",
    "features_train_upsampled, target_train_upsampled = upsample(features_train, target_train, 2)\n",
    "features_train_balanced, target_train_balanced = downsample(features_train_upsampled, target_train_upsampled, 0.75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Обучим модели случайного леса и решающего дерева на сбалансированных обучающих выборках.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Наилучшая метрика f1: 0.623\n",
      "    Парамтеры модели:\n",
      "       n_estimators = 39\n",
      "       max_depth = 12\n",
      "       min_samples_split = 3\n",
      "       min_samples_leaf = 1 \n",
      "\n",
      "Наилучшая метрика roc_auc: 0.857\n",
      "    Парамтеры модели:\n",
      "       n_estimators = 39\n",
      "       max_depth = 12\n",
      "       min_samples_split = 2\n",
      "       min_samples_leaf = 3 \n"
     ]
    }
   ],
   "source": [
    "random_forest(features_train_balanced, features_valid, target_train_balanced, target_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Наилучшая метрика f1: 0.578\n",
      "    Парамтеры модели:\n",
      "       max_depth = 7\n",
      "       min_samples_split = 2\n",
      "       min_samples_leaf = 7\n",
      "       criterion = entropy \n",
      "\n",
      "Наилучшая метрика roc_auc: 0.83\n",
      "    Парамтеры модели:\n",
      "       max_depth = 6\n",
      "       min_samples_split = 2\n",
      "       min_samples_leaf = 8\n",
      "       criterion = entropy \n"
     ]
    }
   ],
   "source": [
    "decision_tree(features_train_balanced, features_valid, target_train_balanced, target_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Метрика f1 для модели \"Случайный лес\" достигла значения 0.623 на сбалансированной выборке, что удовлетворяет условию технического задания (>0.59).\n",
    "- Для модели \"Решающее дерево\" метрика f1 также не достигла минимально допустимого значения 0.578.\n",
    "- Наилучшие значения метрик f1 и roc_auc достигли на случайном лесе при одинаковых значениях гиперпараметров. Для решающего дерева оптимальные значения гиперпараметров различаются.\n",
    "- Максимальное значение метрики roc_auc для случайного леса 0.857 не намного выше, чем для решающего дерева 0.83."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "repeat = 2;   fraction = 0.5\n",
      "Наилучшая метрика f1: 0.57\n",
      "    Парамтеры модели:\n",
      "       max_depth = 8\n",
      "       min_samples_split = 2\n",
      "       min_samples_leaf = 9\n",
      "       criterion = entropy \n",
      "\n",
      "Наилучшая метрика roc_auc: 0.832\n",
      "    Парамтеры модели:\n",
      "       max_depth = 7\n",
      "       min_samples_split = 2\n",
      "       min_samples_leaf = 9\n",
      "       criterion = gini \n",
      " \n",
      "repeat = 2;   fraction = 0.55\n",
      "Наилучшая метрика f1: 0.569\n",
      "    Парамтеры модели:\n",
      "       max_depth = 7\n",
      "       min_samples_split = 2\n",
      "       min_samples_leaf = 1\n",
      "       criterion = gini \n",
      "\n",
      "Наилучшая метрика roc_auc: 0.829\n",
      "    Парамтеры модели:\n",
      "       max_depth = 5\n",
      "       min_samples_split = 2\n",
      "       min_samples_leaf = 1\n",
      "       criterion = gini \n",
      " \n",
      "repeat = 2;   fraction = 0.6\n",
      "Наилучшая метрика f1: 0.574\n",
      "    Парамтеры модели:\n",
      "       max_depth = 7\n",
      "       min_samples_split = 2\n",
      "       min_samples_leaf = 4\n",
      "       criterion = entropy \n",
      "\n",
      "Наилучшая метрика roc_auc: 0.823\n",
      "    Парамтеры модели:\n",
      "       max_depth = 6\n",
      "       min_samples_split = 2\n",
      "       min_samples_leaf = 5\n",
      "       criterion = entropy \n",
      " \n",
      "repeat = 2;   fraction = 0.65\n",
      "Наилучшая метрика f1: 0.569\n",
      "    Парамтеры модели:\n",
      "       max_depth = 7\n",
      "       min_samples_split = 2\n",
      "       min_samples_leaf = 1\n",
      "       criterion = gini \n",
      "\n",
      "Наилучшая метрика roc_auc: 0.826\n",
      "    Парамтеры модели:\n",
      "       max_depth = 5\n",
      "       min_samples_split = 2\n",
      "       min_samples_leaf = 1\n",
      "       criterion = entropy \n",
      " \n",
      "repeat = 2;   fraction = 0.7\n",
      "Наилучшая метрика f1: 0.574\n",
      "    Парамтеры модели:\n",
      "       max_depth = 7\n",
      "       min_samples_split = 2\n",
      "       min_samples_leaf = 1\n",
      "       criterion = gini \n",
      "\n",
      "Наилучшая метрика roc_auc: 0.828\n",
      "    Парамтеры модели:\n",
      "       max_depth = 5\n",
      "       min_samples_split = 5\n",
      "       min_samples_leaf = 1\n",
      "       criterion = entropy \n",
      " \n",
      "repeat = 2;   fraction = 0.75\n",
      "Наилучшая метрика f1: 0.578\n",
      "    Парамтеры модели:\n",
      "       max_depth = 7\n",
      "       min_samples_split = 2\n",
      "       min_samples_leaf = 7\n",
      "       criterion = entropy \n",
      "\n",
      "Наилучшая метрика roc_auc: 0.83\n",
      "    Парамтеры модели:\n",
      "       max_depth = 6\n",
      "       min_samples_split = 2\n",
      "       min_samples_leaf = 8\n",
      "       criterion = entropy \n",
      " \n",
      "repeat = 2;   fraction = 0.8\n",
      "Наилучшая метрика f1: 0.574\n",
      "    Парамтеры модели:\n",
      "       max_depth = 5\n",
      "       min_samples_split = 2\n",
      "       min_samples_leaf = 5\n",
      "       criterion = entropy \n",
      "\n",
      "Наилучшая метрика roc_auc: 0.826\n",
      "    Парамтеры модели:\n",
      "       max_depth = 6\n",
      "       min_samples_split = 2\n",
      "       min_samples_leaf = 3\n",
      "       criterion = gini \n",
      " \n",
      "repeat = 3;   fraction = 0.5\n",
      "Наилучшая метрика f1: 0.545\n",
      "    Парамтеры модели:\n",
      "       max_depth = 9\n",
      "       min_samples_split = 2\n",
      "       min_samples_leaf = 7\n",
      "       criterion = entropy \n",
      "\n",
      "Наилучшая метрика roc_auc: 0.825\n",
      "    Парамтеры модели:\n",
      "       max_depth = 6\n",
      "       min_samples_split = 2\n",
      "       min_samples_leaf = 9\n",
      "       criterion = entropy \n",
      " \n",
      "repeat = 3;   fraction = 0.55\n",
      "Наилучшая метрика f1: 0.549\n",
      "    Парамтеры модели:\n",
      "       max_depth = 9\n",
      "       min_samples_split = 2\n",
      "       min_samples_leaf = 9\n",
      "       criterion = entropy \n",
      "\n",
      "Наилучшая метрика roc_auc: 0.828\n",
      "    Парамтеры модели:\n",
      "       max_depth = 7\n",
      "       min_samples_split = 2\n",
      "       min_samples_leaf = 9\n",
      "       criterion = entropy \n",
      " \n",
      "repeat = 3;   fraction = 0.6\n",
      "Наилучшая метрика f1: 0.572\n",
      "    Парамтеры модели:\n",
      "       max_depth = 7\n",
      "       min_samples_split = 2\n",
      "       min_samples_leaf = 9\n",
      "       criterion = entropy \n",
      "\n",
      "Наилучшая метрика roc_auc: 0.83\n",
      "    Парамтеры модели:\n",
      "       max_depth = 7\n",
      "       min_samples_split = 2\n",
      "       min_samples_leaf = 9\n",
      "       criterion = entropy \n",
      " \n",
      "repeat = 3;   fraction = 0.65\n",
      "Наилучшая метрика f1: 0.571\n",
      "    Парамтеры модели:\n",
      "       max_depth = 5\n",
      "       min_samples_split = 2\n",
      "       min_samples_leaf = 1\n",
      "       criterion = entropy \n",
      "\n",
      "Наилучшая метрика roc_auc: 0.822\n",
      "    Парамтеры модели:\n",
      "       max_depth = 5\n",
      "       min_samples_split = 2\n",
      "       min_samples_leaf = 1\n",
      "       criterion = entropy \n",
      " \n",
      "repeat = 3;   fraction = 0.7\n",
      "Наилучшая метрика f1: 0.571\n",
      "    Парамтеры модели:\n",
      "       max_depth = 5\n",
      "       min_samples_split = 2\n",
      "       min_samples_leaf = 1\n",
      "       criterion = entropy \n",
      "\n",
      "Наилучшая метрика roc_auc: 0.823\n",
      "    Парамтеры модели:\n",
      "       max_depth = 8\n",
      "       min_samples_split = 2\n",
      "       min_samples_leaf = 8\n",
      "       criterion = entropy \n",
      " \n",
      "repeat = 3;   fraction = 0.75\n",
      "Наилучшая метрика f1: 0.572\n",
      "    Парамтеры модели:\n",
      "       max_depth = 5\n",
      "       min_samples_split = 2\n",
      "       min_samples_leaf = 3\n",
      "       criterion = gini \n",
      "\n",
      "Наилучшая метрика roc_auc: 0.824\n",
      "    Парамтеры модели:\n",
      "       max_depth = 6\n",
      "       min_samples_split = 2\n",
      "       min_samples_leaf = 3\n",
      "       criterion = gini \n",
      " \n",
      "repeat = 3;   fraction = 0.8\n",
      "Наилучшая метрика f1: 0.563\n",
      "    Парамтеры модели:\n",
      "       max_depth = 8\n",
      "       min_samples_split = 2\n",
      "       min_samples_leaf = 9\n",
      "       criterion = entropy \n",
      "\n",
      "Наилучшая метрика roc_auc: 0.827\n",
      "    Парамтеры модели:\n",
      "       max_depth = 6\n",
      "       min_samples_split = 2\n",
      "       min_samples_leaf = 6\n",
      "       criterion = gini \n"
     ]
    }
   ],
   "source": [
    "#Для модели случайного леса попробуем применить различные варианты upsampling и downsampling \n",
    "#(изменять параметры repeat и fraction)\n",
    "for rep in range(2,4):\n",
    "    for frac in np.arange(0.5, 0.8, 0.05):\n",
    "        print(' ')\n",
    "        print('repeat = {};   fraction = {}'.format(rep, round(frac,2)))\n",
    "        features_train_upsampled, target_train_upsampled = upsample(features_train, target_train, rep)\n",
    "        features_train_balanced, target_train_balanced = downsample(features_train_upsampled, target_train_upsampled, frac)\n",
    "        decision_tree(features_train_balanced, features_valid, target_train_balanced, target_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наилучший результат для решающего дерева достигнут при увеличении положительного класса тренировочной выборки в 2 раза и сэмплировании отрицательного класса с коэффициентом 0.55. При этом метрика f1 = 0.578 а roc_auc = 0.83, что не удовлетворяет условиям технического задания."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вывод**\n",
    "\n",
    "Взвешивание классов с помощью параметра class_weight не дало значительного увеличения метрики f1.<br>\n",
    "Upsampling положительного класса и downsampling отрицательного класса дали необходимый прирост точности моделей.<br>\n",
    "Необходимое качество на валидационной выборке получили модели:\n",
    "- Случайный лес:\n",
    "  - f1 = 0.623\n",
    "  - roc_auc = 0.857\n",
    "  - repeat = 2 - повторение объектов класса 1\n",
    "  - fraction = 0.75 - коэффициент сэмплирования объектов класса 0\n",
    "- Решающее дерево:\n",
    "  - f1 = 0.574\n",
    "  - roc_auc = 0.83\n",
    "  - repeat = 2\n",
    "  - fraction = 0.55"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Тестирование модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проведём обучение полученных моделей на всех доступных данных (обучающие + валидационные), предварительно сбалансировав классы с найденными ранее коэффициентами repeat и fraction.\n",
    "\n",
    "Вычислим метрики f1 и roc_auc на тестовой выборке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " f1 = 0.59, \n",
      " roc_auc = 0.85\n"
     ]
    }
   ],
   "source": [
    "#Случайный лес\n",
    "\n",
    "features_upsampled, target_upsampled = upsample(features_train, target_train, 2)\n",
    "features_balanced, target_balanced = downsample(features_upsampled, target_upsampled, 0.75)\n",
    "model_forest_1 = RandomForestClassifier(random_state=123,\n",
    "                                         n_estimators=33,\n",
    "                                         max_depth=12,\n",
    "                                         min_samples_split=3,\n",
    "                                         min_samples_leaf=1)\n",
    "model_forest_1.fit(features_balanced, target_balanced)\n",
    "predictions = model_forest_1.predict(features_test)\n",
    "f1 = f1_score(target_test, predictions)\n",
    "roc_auc = roc_auc_score(target_test, model_forest_1.predict_proba(features_test)[:,1])#КОД РЕВЬЮЕРА\n",
    "print(' f1 = {}, \\n roc_auc = {}'.format(round(f1,2), round(roc_auc,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " f1 = 0.57, \n",
      " roc_auc = 0.82\n"
     ]
    }
   ],
   "source": [
    "#Решающее дерево\n",
    "\n",
    "features_upsampled, target_upsampled = upsample(features_train, target_train, 2)\n",
    "features_balanced, target_balanced = downsample(features_upsampled, target_upsampled, 0.75)\n",
    "model_tree_1 = DecisionTreeClassifier(random_state=123,\n",
    "                                         max_depth=8,\n",
    "                                         min_samples_split=2,\n",
    "                                         min_samples_leaf=4)\n",
    "model_tree_1.fit(features_balanced, target_balanced)\n",
    "predictions = model_tree_1.predict(features_test)\n",
    "f1 = f1_score(target_test, predictions)\n",
    "roc_auc = roc_auc_score(target_test, model_tree_1.predict_proba(features_test)[:,1]) #КОД РЕВЬЮЕРА\n",
    "print(' f1 = {}, \\n roc_auc = {}'.format(round(f1,2), round(roc_auc,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Вывод\n",
    "\n",
    "Проведён анализ моделей без учёта дисбаланса классов.\n",
    "- Исходные данные разделены на обучающую, валидационную и тестовую выборки.\n",
    "- Обучены модели \"Решающее Дерево\", \"Случайный лес\", \"Логистическая Регрессия\" без учёта дисбаланса классов. Максимальное значение метрики f1 = 0.586 получено при обучении модели случайного леса.\n",
    "- Качество моделей также оценено по метрике roc_auc. Максимальное значение метрики roc_auc = 0.859 достигнуто при обучении модели случайного леса.\n",
    "- Метрики f1 и roc_auc достигли максимальных значений при одинаковых настройках гиперпараметров.\n",
    "\n",
    "Проведён анализ дисбаланса классов\n",
    "- Взвешивание классов с помощью параметра class_weight не дало значительного увеличения метрики f1.\n",
    "- Upsampling положительного класса и downsampling отрицательного класса дали необходимый прирост точности моделей.\n",
    "- Необходимое значение f1 на валидационной выборке получили модели:\n",
    " - Случайный лес:\n",
    "  - f1 = 0.623\n",
    "  - roc_auc = 0.857\n",
    " - Решающее дерево:\n",
    "  - f1 = 0.574\n",
    "  - roc_auc = 0.83\n",
    "  \n",
    "Проведено тестирование полученных моделей на тестовой выборке:\n",
    "- Значение метрики f1 на тестовой выборке совпадают:\n",
    "  - f1 = 0.59\n",
    "  - roc_auc = 0.74"
   ]
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 1095,
    "start_time": "2022-02-26T16:45:22.151Z"
   },
   {
    "duration": 66,
    "start_time": "2022-02-26T17:08:18.628Z"
   },
   {
    "duration": 10,
    "start_time": "2022-02-26T17:08:38.346Z"
   },
   {
    "duration": 356,
    "start_time": "2022-03-09T14:15:46.688Z"
   },
   {
    "duration": 991,
    "start_time": "2022-03-09T14:15:52.224Z"
   },
   {
    "duration": 43,
    "start_time": "2022-03-09T14:15:53.917Z"
   },
   {
    "duration": 8,
    "start_time": "2022-03-09T14:15:55.422Z"
   },
   {
    "duration": 7,
    "start_time": "2022-03-09T14:15:56.830Z"
   },
   {
    "duration": 10,
    "start_time": "2022-03-09T14:17:06.532Z"
   },
   {
    "duration": 20,
    "start_time": "2022-03-09T14:17:19.639Z"
   },
   {
    "duration": 358,
    "start_time": "2022-03-09T14:52:35.558Z"
   },
   {
    "duration": 4,
    "start_time": "2022-03-09T14:52:49.146Z"
   },
   {
    "duration": 23,
    "start_time": "2022-03-09T14:58:07.908Z"
   },
   {
    "duration": 4,
    "start_time": "2022-03-09T14:59:05.306Z"
   },
   {
    "duration": 5,
    "start_time": "2022-03-09T14:59:24.113Z"
   },
   {
    "duration": 3,
    "start_time": "2022-03-09T15:03:32.114Z"
   },
   {
    "duration": 305,
    "start_time": "2022-03-09T15:03:51.140Z"
   },
   {
    "duration": 33,
    "start_time": "2022-03-09T15:03:57.524Z"
   },
   {
    "duration": 30,
    "start_time": "2022-03-09T15:04:43.241Z"
   },
   {
    "duration": 329,
    "start_time": "2022-03-09T15:09:59.892Z"
   },
   {
    "duration": 305,
    "start_time": "2022-03-09T15:10:05.087Z"
   },
   {
    "duration": 12,
    "start_time": "2022-03-09T15:10:12.213Z"
   },
   {
    "duration": 49,
    "start_time": "2022-03-09T15:10:54.842Z"
   },
   {
    "duration": 10,
    "start_time": "2022-03-09T15:12:11.767Z"
   },
   {
    "duration": 437,
    "start_time": "2022-03-09T15:17:59.748Z"
   },
   {
    "duration": 11,
    "start_time": "2022-03-09T15:18:10.093Z"
   },
   {
    "duration": 316,
    "start_time": "2022-03-09T15:19:06.537Z"
   },
   {
    "duration": 334,
    "start_time": "2022-03-09T15:21:21.812Z"
   },
   {
    "duration": 334,
    "start_time": "2022-03-09T15:21:33.882Z"
   },
   {
    "duration": 6,
    "start_time": "2022-03-09T15:21:44.566Z"
   },
   {
    "duration": 3,
    "start_time": "2022-03-09T15:21:53.916Z"
   },
   {
    "duration": 5,
    "start_time": "2022-03-09T15:22:19.162Z"
   },
   {
    "duration": 6103,
    "start_time": "2022-03-09T15:26:00.135Z"
   },
   {
    "duration": 4,
    "start_time": "2022-03-09T15:27:29.263Z"
   },
   {
    "duration": 3,
    "start_time": "2022-03-09T15:30:29.973Z"
   },
   {
    "duration": 4,
    "start_time": "2022-03-09T15:30:54.987Z"
   },
   {
    "duration": 666,
    "start_time": "2022-03-09T15:32:10.444Z"
   },
   {
    "duration": 983,
    "start_time": "2022-03-10T11:32:57.035Z"
   },
   {
    "duration": 5949,
    "start_time": "2022-03-10T11:33:00.247Z"
   },
   {
    "duration": 60,
    "start_time": "2022-03-10T11:33:06.198Z"
   },
   {
    "duration": 9,
    "start_time": "2022-03-10T11:33:07.116Z"
   },
   {
    "duration": 7,
    "start_time": "2022-03-10T11:33:08.377Z"
   },
   {
    "duration": 11,
    "start_time": "2022-03-10T11:33:08.941Z"
   },
   {
    "duration": 20,
    "start_time": "2022-03-10T11:33:09.370Z"
   },
   {
    "duration": 4,
    "start_time": "2022-03-10T11:33:09.822Z"
   },
   {
    "duration": 23,
    "start_time": "2022-03-10T11:33:09.988Z"
   },
   {
    "duration": 4,
    "start_time": "2022-03-10T11:33:10.271Z"
   },
   {
    "duration": 6,
    "start_time": "2022-03-10T11:33:10.418Z"
   },
   {
    "duration": 31,
    "start_time": "2022-03-10T11:33:11.312Z"
   },
   {
    "duration": 12,
    "start_time": "2022-03-10T11:33:12.191Z"
   },
   {
    "duration": 52,
    "start_time": "2022-03-10T11:33:12.627Z"
   },
   {
    "duration": 9,
    "start_time": "2022-03-10T11:33:13.546Z"
   },
   {
    "duration": 11,
    "start_time": "2022-03-10T11:33:15.918Z"
   },
   {
    "duration": 3,
    "start_time": "2022-03-10T11:33:17.295Z"
   },
   {
    "duration": 4,
    "start_time": "2022-03-10T11:33:18.635Z"
   },
   {
    "duration": 3,
    "start_time": "2022-03-10T11:33:21.102Z"
   },
   {
    "duration": 4,
    "start_time": "2022-03-10T11:33:22.655Z"
   },
   {
    "duration": 744,
    "start_time": "2022-03-10T11:33:25.298Z"
   },
   {
    "duration": 195,
    "start_time": "2022-03-10T12:11:53.795Z"
   },
   {
    "duration": 1106,
    "start_time": "2022-03-10T12:12:10.365Z"
   },
   {
    "duration": 4,
    "start_time": "2022-03-10T12:15:33.801Z"
   },
   {
    "duration": 2405,
    "start_time": "2022-03-10T12:29:58.601Z"
   },
   {
    "duration": 46,
    "start_time": "2022-03-10T12:30:26.621Z"
   },
   {
    "duration": 8,
    "start_time": "2022-03-10T12:44:34.767Z"
   },
   {
    "duration": 10,
    "start_time": "2022-03-10T12:44:45.788Z"
   },
   {
    "duration": 286,
    "start_time": "2022-03-10T12:44:54.251Z"
   },
   {
    "duration": 20,
    "start_time": "2022-03-10T12:44:57.304Z"
   },
   {
    "duration": 4,
    "start_time": "2022-03-10T12:47:24.903Z"
   },
   {
    "duration": 14,
    "start_time": "2022-03-10T12:51:09.975Z"
   },
   {
    "duration": 55,
    "start_time": "2022-03-10T12:51:46.030Z"
   },
   {
    "duration": 304,
    "start_time": "2022-03-10T12:52:07.682Z"
   },
   {
    "duration": 1078,
    "start_time": "2022-03-10T12:52:23.802Z"
   },
   {
    "duration": 58,
    "start_time": "2022-03-10T12:52:25.204Z"
   },
   {
    "duration": 7,
    "start_time": "2022-03-10T12:52:26.404Z"
   },
   {
    "duration": 10,
    "start_time": "2022-03-10T12:52:27.602Z"
   },
   {
    "duration": 19,
    "start_time": "2022-03-10T12:52:28.082Z"
   },
   {
    "duration": 12,
    "start_time": "2022-03-10T12:52:31.954Z"
   },
   {
    "duration": 55,
    "start_time": "2022-03-10T12:52:33.100Z"
   },
   {
    "duration": 4,
    "start_time": "2022-03-10T12:52:33.962Z"
   },
   {
    "duration": 1118,
    "start_time": "2022-03-10T12:53:17.335Z"
   },
   {
    "duration": 44,
    "start_time": "2022-03-10T12:53:18.455Z"
   },
   {
    "duration": 8,
    "start_time": "2022-03-10T12:53:18.765Z"
   },
   {
    "duration": 11,
    "start_time": "2022-03-10T12:53:19.758Z"
   },
   {
    "duration": 21,
    "start_time": "2022-03-10T12:53:20.237Z"
   },
   {
    "duration": 5,
    "start_time": "2022-03-10T12:53:25.642Z"
   },
   {
    "duration": 97,
    "start_time": "2022-03-10T12:54:06.714Z"
   },
   {
    "duration": 23,
    "start_time": "2022-03-10T12:54:14.260Z"
   },
   {
    "duration": 5,
    "start_time": "2022-03-10T12:58:38.596Z"
   },
   {
    "duration": 5,
    "start_time": "2022-03-10T12:58:51.776Z"
   },
   {
    "duration": 33,
    "start_time": "2022-03-10T12:59:44.734Z"
   },
   {
    "duration": 13,
    "start_time": "2022-03-10T13:00:00.513Z"
   },
   {
    "duration": 58,
    "start_time": "2022-03-10T13:00:02.238Z"
   },
   {
    "duration": 11,
    "start_time": "2022-03-10T13:00:57.420Z"
   },
   {
    "duration": 103,
    "start_time": "2022-03-10T13:01:48.811Z"
   },
   {
    "duration": 4,
    "start_time": "2022-03-10T13:02:36.410Z"
   },
   {
    "duration": 10,
    "start_time": "2022-03-10T13:03:34.303Z"
   },
   {
    "duration": 10,
    "start_time": "2022-03-10T13:03:41.109Z"
   },
   {
    "duration": 5,
    "start_time": "2022-03-10T13:04:08.532Z"
   },
   {
    "duration": 7,
    "start_time": "2022-03-10T13:10:41.452Z"
   },
   {
    "duration": 772,
    "start_time": "2022-03-10T13:11:01.996Z"
   },
   {
    "duration": 6,
    "start_time": "2022-03-10T13:12:59.731Z"
   },
   {
    "duration": 657,
    "start_time": "2022-03-10T13:13:02.003Z"
   },
   {
    "duration": 505,
    "start_time": "2022-03-10T13:14:01.733Z"
   },
   {
    "duration": 571,
    "start_time": "2022-03-10T13:44:30.647Z"
   },
   {
    "duration": 500,
    "start_time": "2022-03-10T13:54:18.560Z"
   },
   {
    "duration": 667,
    "start_time": "2022-03-10T13:55:25.100Z"
   },
   {
    "duration": 514,
    "start_time": "2022-03-10T13:59:29.886Z"
   },
   {
    "duration": 540,
    "start_time": "2022-03-10T14:00:50.172Z"
   },
   {
    "duration": 1087,
    "start_time": "2022-03-10T14:05:22.302Z"
   },
   {
    "duration": 43,
    "start_time": "2022-03-10T14:05:23.391Z"
   },
   {
    "duration": 7,
    "start_time": "2022-03-10T14:05:24.371Z"
   },
   {
    "duration": 10,
    "start_time": "2022-03-10T14:05:25.264Z"
   },
   {
    "duration": 20,
    "start_time": "2022-03-10T14:05:25.876Z"
   },
   {
    "duration": 4,
    "start_time": "2022-03-10T14:05:28.134Z"
   },
   {
    "duration": 22,
    "start_time": "2022-03-10T14:05:28.579Z"
   },
   {
    "duration": 4,
    "start_time": "2022-03-10T14:05:31.244Z"
   },
   {
    "duration": 6,
    "start_time": "2022-03-10T14:05:31.670Z"
   },
   {
    "duration": 31,
    "start_time": "2022-03-10T14:05:32.601Z"
   },
   {
    "duration": 12,
    "start_time": "2022-03-10T14:05:34.798Z"
   },
   {
    "duration": 48,
    "start_time": "2022-03-10T14:05:35.554Z"
   },
   {
    "duration": 10,
    "start_time": "2022-03-10T14:05:37.510Z"
   },
   {
    "duration": 398,
    "start_time": "2022-03-10T14:05:51.804Z"
   },
   {
    "duration": 300,
    "start_time": "2022-03-10T14:06:02.629Z"
   },
   {
    "duration": 10,
    "start_time": "2022-03-10T14:06:08.428Z"
   },
   {
    "duration": 4,
    "start_time": "2022-03-10T14:06:22.166Z"
   },
   {
    "duration": 284,
    "start_time": "2022-03-10T14:06:53.960Z"
   },
   {
    "duration": 496,
    "start_time": "2022-03-10T14:07:01.682Z"
   },
   {
    "duration": 481,
    "start_time": "2022-03-10T14:08:40.417Z"
   },
   {
    "duration": 333,
    "start_time": "2022-03-10T14:13:25.685Z"
   },
   {
    "duration": 1032,
    "start_time": "2022-03-10T14:13:37.039Z"
   },
   {
    "duration": 44,
    "start_time": "2022-03-10T14:13:38.073Z"
   },
   {
    "duration": 6,
    "start_time": "2022-03-10T14:13:38.119Z"
   },
   {
    "duration": 25,
    "start_time": "2022-03-10T14:13:38.126Z"
   },
   {
    "duration": 24,
    "start_time": "2022-03-10T14:13:38.152Z"
   },
   {
    "duration": 15,
    "start_time": "2022-03-10T14:13:38.177Z"
   },
   {
    "duration": 23,
    "start_time": "2022-03-10T14:13:38.206Z"
   },
   {
    "duration": 4,
    "start_time": "2022-03-10T14:13:39.118Z"
   },
   {
    "duration": 5,
    "start_time": "2022-03-10T14:13:39.446Z"
   },
   {
    "duration": 31,
    "start_time": "2022-03-10T14:13:40.415Z"
   },
   {
    "duration": 12,
    "start_time": "2022-03-10T14:13:41.209Z"
   },
   {
    "duration": 49,
    "start_time": "2022-03-10T14:13:41.895Z"
   },
   {
    "duration": 10,
    "start_time": "2022-03-10T14:13:42.882Z"
   },
   {
    "duration": 11,
    "start_time": "2022-03-10T14:13:47.643Z"
   },
   {
    "duration": 4,
    "start_time": "2022-03-10T14:13:48.857Z"
   },
   {
    "duration": 581,
    "start_time": "2022-03-10T14:13:51.437Z"
   },
   {
    "duration": 1082,
    "start_time": "2022-03-10T14:16:53.895Z"
   },
   {
    "duration": 44,
    "start_time": "2022-03-10T14:16:54.979Z"
   },
   {
    "duration": 7,
    "start_time": "2022-03-10T14:16:55.999Z"
   },
   {
    "duration": 11,
    "start_time": "2022-03-10T14:16:57.271Z"
   },
   {
    "duration": 20,
    "start_time": "2022-03-10T14:16:57.667Z"
   },
   {
    "duration": 4,
    "start_time": "2022-03-10T14:17:00.781Z"
   },
   {
    "duration": 1107,
    "start_time": "2022-03-10T14:18:19.098Z"
   },
   {
    "duration": 4,
    "start_time": "2022-03-10T14:20:40.139Z"
   },
   {
    "duration": 1122,
    "start_time": "2022-03-10T14:20:44.035Z"
   },
   {
    "duration": 1053,
    "start_time": "2022-03-10T14:22:23.708Z"
   },
   {
    "duration": 1069,
    "start_time": "2022-03-10T14:22:53.545Z"
   },
   {
    "duration": 5,
    "start_time": "2022-03-10T14:25:05.081Z"
   },
   {
    "duration": 1100,
    "start_time": "2022-03-10T14:25:10.469Z"
   },
   {
    "duration": 22,
    "start_time": "2022-03-10T14:29:09.602Z"
   },
   {
    "duration": 4,
    "start_time": "2022-03-10T14:29:13.072Z"
   },
   {
    "duration": 5,
    "start_time": "2022-03-10T14:29:13.415Z"
   },
   {
    "duration": 30,
    "start_time": "2022-03-10T14:29:13.908Z"
   },
   {
    "duration": 11,
    "start_time": "2022-03-10T14:29:15.625Z"
   },
   {
    "duration": 50,
    "start_time": "2022-03-10T14:29:16.161Z"
   },
   {
    "duration": 330,
    "start_time": "2022-03-10T14:29:16.798Z"
   },
   {
    "duration": 10,
    "start_time": "2022-03-10T14:29:26.639Z"
   },
   {
    "duration": 310,
    "start_time": "2022-03-10T14:29:55.345Z"
   },
   {
    "duration": 13,
    "start_time": "2022-03-10T14:30:05.088Z"
   },
   {
    "duration": 5,
    "start_time": "2022-03-10T14:30:07.195Z"
   },
   {
    "duration": 687,
    "start_time": "2022-03-10T14:30:11.410Z"
   },
   {
    "duration": 1095,
    "start_time": "2022-03-10T14:32:26.965Z"
   },
   {
    "duration": 44,
    "start_time": "2022-03-10T14:32:28.061Z"
   },
   {
    "duration": 6,
    "start_time": "2022-03-10T14:32:28.107Z"
   },
   {
    "duration": 11,
    "start_time": "2022-03-10T14:32:28.114Z"
   },
   {
    "duration": 17,
    "start_time": "2022-03-10T14:32:28.127Z"
   },
   {
    "duration": 3,
    "start_time": "2022-03-10T14:32:28.146Z"
   },
   {
    "duration": 19,
    "start_time": "2022-03-10T14:32:28.150Z"
   },
   {
    "duration": 4,
    "start_time": "2022-03-10T14:32:28.836Z"
   },
   {
    "duration": 5,
    "start_time": "2022-03-10T14:32:29.151Z"
   },
   {
    "duration": 31,
    "start_time": "2022-03-10T14:32:29.616Z"
   },
   {
    "duration": 13,
    "start_time": "2022-03-10T14:32:30.743Z"
   },
   {
    "duration": 47,
    "start_time": "2022-03-10T14:32:31.385Z"
   },
   {
    "duration": 8,
    "start_time": "2022-03-10T14:32:32.416Z"
   },
   {
    "duration": 9,
    "start_time": "2022-03-10T14:32:38.113Z"
   },
   {
    "duration": 4,
    "start_time": "2022-03-10T14:32:39.614Z"
   },
   {
    "duration": 586,
    "start_time": "2022-03-10T14:32:41.622Z"
   },
   {
    "duration": 511,
    "start_time": "2022-03-10T14:33:49.326Z"
   },
   {
    "duration": 5,
    "start_time": "2022-03-10T14:39:05.995Z"
   },
   {
    "duration": 10,
    "start_time": "2022-03-10T14:39:23.305Z"
   },
   {
    "duration": 3,
    "start_time": "2022-03-10T14:39:25.820Z"
   },
   {
    "duration": 672,
    "start_time": "2022-03-10T14:39:28.135Z"
   },
   {
    "duration": 10,
    "start_time": "2022-03-10T14:39:49.301Z"
   },
   {
    "duration": 560,
    "start_time": "2022-03-10T14:39:52.359Z"
   },
   {
    "duration": 1095,
    "start_time": "2022-03-10T14:42:31.285Z"
   },
   {
    "duration": 44,
    "start_time": "2022-03-10T14:42:32.381Z"
   },
   {
    "duration": 6,
    "start_time": "2022-03-10T14:42:32.426Z"
   },
   {
    "duration": 10,
    "start_time": "2022-03-10T14:42:32.433Z"
   },
   {
    "duration": 19,
    "start_time": "2022-03-10T14:42:32.516Z"
   },
   {
    "duration": 4,
    "start_time": "2022-03-10T14:42:32.822Z"
   },
   {
    "duration": 22,
    "start_time": "2022-03-10T14:42:33.678Z"
   },
   {
    "duration": 4,
    "start_time": "2022-03-10T14:42:35.101Z"
   },
   {
    "duration": 6,
    "start_time": "2022-03-10T14:42:35.560Z"
   },
   {
    "duration": 30,
    "start_time": "2022-03-10T14:42:36.476Z"
   },
   {
    "duration": 12,
    "start_time": "2022-03-10T14:42:37.682Z"
   },
   {
    "duration": 47,
    "start_time": "2022-03-10T14:42:38.325Z"
   },
   {
    "duration": 8,
    "start_time": "2022-03-10T14:42:38.980Z"
   },
   {
    "duration": 7546,
    "start_time": "2022-03-10T14:42:43.258Z"
   },
   {
    "duration": 11,
    "start_time": "2022-03-10T14:43:01.213Z"
   },
   {
    "duration": 12,
    "start_time": "2022-03-10T14:45:57.733Z"
   },
   {
    "duration": 534,
    "start_time": "2022-03-10T14:48:51.867Z"
   },
   {
    "duration": 1111,
    "start_time": "2022-03-10T14:51:23.775Z"
   },
   {
    "duration": 45,
    "start_time": "2022-03-10T14:51:24.888Z"
   },
   {
    "duration": 7,
    "start_time": "2022-03-10T14:51:26.915Z"
   },
   {
    "duration": 12,
    "start_time": "2022-03-10T14:51:27.207Z"
   },
   {
    "duration": 19,
    "start_time": "2022-03-10T14:51:28.748Z"
   },
   {
    "duration": 5,
    "start_time": "2022-03-10T14:51:33.369Z"
   },
   {
    "duration": 22,
    "start_time": "2022-03-10T14:51:36.599Z"
   },
   {
    "duration": 4,
    "start_time": "2022-03-10T14:51:37.382Z"
   },
   {
    "duration": 6,
    "start_time": "2022-03-10T14:51:38.051Z"
   },
   {
    "duration": 32,
    "start_time": "2022-03-10T14:51:40.888Z"
   },
   {
    "duration": 379,
    "start_time": "2022-03-10T14:52:17.958Z"
   },
   {
    "duration": 354,
    "start_time": "2022-03-10T14:52:35.160Z"
   },
   {
    "duration": 10,
    "start_time": "2022-03-10T14:52:45.549Z"
   },
   {
    "duration": 309,
    "start_time": "2022-03-10T14:54:47.525Z"
   },
   {
    "duration": 48916,
    "start_time": "2022-03-10T14:54:55.429Z"
   },
   {
    "duration": 4,
    "start_time": "2022-03-10T14:55:44.361Z"
   },
   {
    "duration": 305,
    "start_time": "2022-03-10T14:56:58.851Z"
   },
   {
    "duration": 25,
    "start_time": "2022-03-10T14:57:04.398Z"
   },
   {
    "duration": 7382,
    "start_time": "2022-03-10T14:57:24.809Z"
   },
   {
    "duration": 7525,
    "start_time": "2022-03-10T14:57:33.976Z"
   },
   {
    "duration": -125,
    "start_time": "2022-03-10T14:57:41.628Z"
   },
   {
    "duration": 17,
    "start_time": "2022-03-10T14:57:50.803Z"
   },
   {
    "duration": 8403,
    "start_time": "2022-03-10T14:57:54.969Z"
   },
   {
    "duration": 1107,
    "start_time": "2022-03-10T14:58:28.770Z"
   },
   {
    "duration": 55,
    "start_time": "2022-03-10T14:58:29.878Z"
   },
   {
    "duration": 5,
    "start_time": "2022-03-10T14:58:29.935Z"
   },
   {
    "duration": 11,
    "start_time": "2022-03-10T14:58:29.942Z"
   },
   {
    "duration": 18,
    "start_time": "2022-03-10T14:58:29.954Z"
   },
   {
    "duration": 4,
    "start_time": "2022-03-10T14:58:29.973Z"
   },
   {
    "duration": 19,
    "start_time": "2022-03-10T14:58:30.078Z"
   },
   {
    "duration": 4,
    "start_time": "2022-03-10T14:58:30.837Z"
   },
   {
    "duration": 6,
    "start_time": "2022-03-10T14:58:31.147Z"
   },
   {
    "duration": 31,
    "start_time": "2022-03-10T14:58:32.362Z"
   },
   {
    "duration": 10,
    "start_time": "2022-03-10T14:58:33.167Z"
   },
   {
    "duration": 50750,
    "start_time": "2022-03-10T14:58:33.792Z"
   },
   {
    "duration": 3,
    "start_time": "2022-03-10T14:59:24.544Z"
   },
   {
    "duration": 22,
    "start_time": "2022-03-10T14:59:24.549Z"
   },
   {
    "duration": 15,
    "start_time": "2022-03-10T14:59:24.573Z"
   },
   {
    "duration": 11,
    "start_time": "2022-03-10T15:01:09.181Z"
   },
   {
    "duration": 9540,
    "start_time": "2022-03-10T15:01:14.204Z"
   },
   {
    "duration": 58690,
    "start_time": "2022-03-10T15:06:57.217Z"
   },
   {
    "duration": 19619,
    "start_time": "2022-03-10T15:11:19.487Z"
   },
   {
    "duration": 19589,
    "start_time": "2022-03-10T15:11:54.433Z"
   },
   {
    "duration": 80,
    "start_time": "2022-03-10T15:12:14.028Z"
   },
   {
    "duration": 9779,
    "start_time": "2022-03-10T15:15:41.874Z"
   },
   {
    "duration": 4,
    "start_time": "2022-03-10T15:17:49.076Z"
   },
   {
    "duration": 3,
    "start_time": "2022-03-10T15:18:03.997Z"
   },
   {
    "duration": 17,
    "start_time": "2022-03-10T15:19:06.047Z"
   },
   {
    "duration": 59579,
    "start_time": "2022-03-10T15:20:11.458Z"
   },
   {
    "duration": 9393,
    "start_time": "2022-03-10T15:21:11.039Z"
   },
   {
    "duration": 132017,
    "start_time": "2022-03-10T15:24:04.609Z"
   },
   {
    "duration": 378,
    "start_time": "2022-03-10T15:28:47.458Z"
   },
   {
    "duration": 313,
    "start_time": "2022-03-10T15:29:14.820Z"
   },
   {
    "duration": 314,
    "start_time": "2022-03-10T15:30:08.411Z"
   },
   {
    "duration": 989,
    "start_time": "2022-03-10T15:30:48.885Z"
   },
   {
    "duration": 440,
    "start_time": "2022-03-10T15:30:54.687Z"
   },
   {
    "duration": 919,
    "start_time": "2022-03-10T15:30:58.553Z"
   },
   {
    "duration": 310,
    "start_time": "2022-03-10T15:32:39.979Z"
   },
   {
    "duration": 99,
    "start_time": "2022-03-10T15:34:22.834Z"
   },
   {
    "duration": 191,
    "start_time": "2022-03-10T15:35:05.708Z"
   },
   {
    "duration": 100,
    "start_time": "2022-03-10T15:35:24.201Z"
   },
   {
    "duration": 536,
    "start_time": "2022-03-10T15:35:43.391Z"
   },
   {
    "duration": 119,
    "start_time": "2022-03-10T15:35:55.981Z"
   },
   {
    "duration": 95,
    "start_time": "2022-03-10T15:37:27.787Z"
   },
   {
    "duration": 1081,
    "start_time": "2022-03-11T11:42:41.957Z"
   },
   {
    "duration": 39,
    "start_time": "2022-03-11T11:42:44.540Z"
   },
   {
    "duration": 7,
    "start_time": "2022-03-11T11:42:46.297Z"
   },
   {
    "duration": 11,
    "start_time": "2022-03-11T11:42:46.957Z"
   },
   {
    "duration": 22,
    "start_time": "2022-03-11T11:42:47.448Z"
   },
   {
    "duration": 5,
    "start_time": "2022-03-11T11:42:49.265Z"
   },
   {
    "duration": 21,
    "start_time": "2022-03-11T11:42:49.985Z"
   },
   {
    "duration": 4,
    "start_time": "2022-03-11T11:42:51.384Z"
   },
   {
    "duration": 6,
    "start_time": "2022-03-11T11:42:51.568Z"
   },
   {
    "duration": 34,
    "start_time": "2022-03-11T11:42:52.025Z"
   },
   {
    "duration": 12,
    "start_time": "2022-03-11T11:42:53.528Z"
   },
   {
    "duration": 54132,
    "start_time": "2022-03-11T11:42:54.501Z"
   },
   {
    "duration": 4,
    "start_time": "2022-03-11T11:43:48.635Z"
   },
   {
    "duration": 23,
    "start_time": "2022-03-11T11:43:48.641Z"
   },
   {
    "duration": 15,
    "start_time": "2022-03-11T11:43:48.666Z"
   },
   {
    "duration": 13,
    "start_time": "2022-03-11T11:43:57.404Z"
   },
   {
    "duration": 420,
    "start_time": "2022-03-11T11:45:06.148Z"
   },
   {
    "duration": 459,
    "start_time": "2022-03-11T11:45:41.189Z"
   },
   {
    "duration": 1624,
    "start_time": "2022-03-11T14:18:32.865Z"
   },
   {
    "duration": 58,
    "start_time": "2022-03-11T14:18:34.492Z"
   },
   {
    "duration": 10,
    "start_time": "2022-03-11T14:18:34.554Z"
   },
   {
    "duration": 34,
    "start_time": "2022-03-11T14:18:34.566Z"
   },
   {
    "duration": 39,
    "start_time": "2022-03-11T14:18:34.602Z"
   },
   {
    "duration": 6,
    "start_time": "2022-03-11T14:18:34.644Z"
   },
   {
    "duration": 74,
    "start_time": "2022-03-11T14:18:34.653Z"
   },
   {
    "duration": 6,
    "start_time": "2022-03-11T14:18:34.731Z"
   },
   {
    "duration": 9,
    "start_time": "2022-03-11T14:18:34.741Z"
   },
   {
    "duration": 78,
    "start_time": "2022-03-11T14:18:34.752Z"
   },
   {
    "duration": 16,
    "start_time": "2022-03-11T14:18:34.832Z"
   },
   {
    "duration": 90952,
    "start_time": "2022-03-11T14:18:34.851Z"
   },
   {
    "duration": 5,
    "start_time": "2022-03-11T14:20:05.806Z"
   },
   {
    "duration": 50,
    "start_time": "2022-03-11T14:20:05.813Z"
   },
   {
    "duration": 42,
    "start_time": "2022-03-11T14:20:05.865Z"
   },
   {
    "duration": 19,
    "start_time": "2022-03-11T14:20:05.909Z"
   },
   {
    "duration": 668,
    "start_time": "2022-03-11T14:20:05.930Z"
   },
   {
    "duration": 1164,
    "start_time": "2022-03-12T08:18:57.410Z"
   },
   {
    "duration": 55,
    "start_time": "2022-03-12T08:18:58.576Z"
   },
   {
    "duration": 8,
    "start_time": "2022-03-12T08:18:58.633Z"
   },
   {
    "duration": 10,
    "start_time": "2022-03-12T08:18:58.643Z"
   },
   {
    "duration": 21,
    "start_time": "2022-03-12T08:18:58.654Z"
   },
   {
    "duration": 5,
    "start_time": "2022-03-12T08:18:58.677Z"
   },
   {
    "duration": 18,
    "start_time": "2022-03-12T08:18:58.705Z"
   },
   {
    "duration": 4,
    "start_time": "2022-03-12T08:18:58.725Z"
   },
   {
    "duration": 5,
    "start_time": "2022-03-12T08:18:58.730Z"
   },
   {
    "duration": 29,
    "start_time": "2022-03-12T08:18:58.737Z"
   },
   {
    "duration": 9,
    "start_time": "2022-03-12T08:18:58.768Z"
   },
   {
    "duration": 49736,
    "start_time": "2022-03-12T08:18:58.806Z"
   },
   {
    "duration": 4,
    "start_time": "2022-03-12T08:19:48.544Z"
   },
   {
    "duration": 24,
    "start_time": "2022-03-12T08:19:48.550Z"
   },
   {
    "duration": 33,
    "start_time": "2022-03-12T08:19:48.575Z"
   },
   {
    "duration": 11,
    "start_time": "2022-03-12T08:19:48.610Z"
   },
   {
    "duration": 646,
    "start_time": "2022-03-12T08:19:48.623Z"
   },
   {
    "duration": 9821,
    "start_time": "2022-03-12T08:26:00.116Z"
   },
   {
    "duration": 1521,
    "start_time": "2022-03-12T09:30:06.456Z"
   },
   {
    "duration": 59,
    "start_time": "2022-03-12T09:30:07.980Z"
   },
   {
    "duration": 11,
    "start_time": "2022-03-12T09:30:09.156Z"
   },
   {
    "duration": 16,
    "start_time": "2022-03-12T09:30:09.471Z"
   },
   {
    "duration": 32,
    "start_time": "2022-03-12T09:30:09.670Z"
   },
   {
    "duration": 7,
    "start_time": "2022-03-12T09:30:10.143Z"
   },
   {
    "duration": 35,
    "start_time": "2022-03-12T09:30:10.645Z"
   },
   {
    "duration": 6,
    "start_time": "2022-03-12T09:30:11.200Z"
   },
   {
    "duration": 7,
    "start_time": "2022-03-12T09:30:11.529Z"
   },
   {
    "duration": 56,
    "start_time": "2022-03-12T09:30:12.357Z"
   },
   {
    "duration": 17,
    "start_time": "2022-03-12T09:30:15.590Z"
   },
   {
    "duration": 81438,
    "start_time": "2022-03-12T09:30:16.137Z"
   },
   {
    "duration": 7,
    "start_time": "2022-03-12T09:31:37.578Z"
   },
   {
    "duration": 64,
    "start_time": "2022-03-12T09:31:37.589Z"
   },
   {
    "duration": 29,
    "start_time": "2022-03-12T09:31:37.656Z"
   },
   {
    "duration": 20,
    "start_time": "2022-03-12T09:31:37.688Z"
   },
   {
    "duration": 15133,
    "start_time": "2022-03-12T09:31:37.711Z"
   },
   {
    "duration": 2404,
    "start_time": "2022-03-12T09:31:58.519Z"
   },
   {
    "duration": 104979,
    "start_time": "2022-03-12T09:32:20.178Z"
   },
   {
    "duration": 20158,
    "start_time": "2022-03-12T09:35:37.494Z"
   },
   {
    "duration": 7,
    "start_time": "2022-03-12T09:38:37.136Z"
   },
   {
    "duration": 16353,
    "start_time": "2022-03-12T09:39:01.371Z"
   },
   {
    "duration": 7,
    "start_time": "2022-03-12T09:39:26.783Z"
   },
   {
    "duration": 6,
    "start_time": "2022-03-12T09:39:28.227Z"
   },
   {
    "duration": 30,
    "start_time": "2022-03-12T09:39:35.005Z"
   },
   {
    "duration": 108562,
    "start_time": "2022-03-12T09:39:38.823Z"
   },
   {
    "duration": 15631,
    "start_time": "2022-03-12T09:41:27.388Z"
   },
   {
    "duration": 211891,
    "start_time": "2022-03-12T09:43:53.569Z"
   },
   {
    "duration": 288,
    "start_time": "2022-03-12T09:50:00.414Z"
   },
   {
    "duration": 284,
    "start_time": "2022-03-12T09:50:56.095Z"
   },
   {
    "duration": 1488,
    "start_time": "2022-03-12T10:09:55.254Z"
   },
   {
    "duration": 48,
    "start_time": "2022-03-12T10:09:56.744Z"
   },
   {
    "duration": 11,
    "start_time": "2022-03-12T10:09:56.796Z"
   },
   {
    "duration": 15,
    "start_time": "2022-03-12T10:09:56.808Z"
   },
   {
    "duration": 8,
    "start_time": "2022-03-12T10:09:56.825Z"
   },
   {
    "duration": 4,
    "start_time": "2022-03-12T10:09:56.834Z"
   },
   {
    "duration": 16,
    "start_time": "2022-03-12T10:09:56.840Z"
   },
   {
    "duration": 3,
    "start_time": "2022-03-12T10:09:56.858Z"
   },
   {
    "duration": 5,
    "start_time": "2022-03-12T10:09:56.862Z"
   },
   {
    "duration": 52,
    "start_time": "2022-03-12T10:09:56.868Z"
   },
   {
    "duration": 8,
    "start_time": "2022-03-12T10:09:56.921Z"
   },
   {
    "duration": 50865,
    "start_time": "2022-03-12T10:09:56.931Z"
   },
   {
    "duration": 7,
    "start_time": "2022-03-12T10:10:47.798Z"
   },
   {
    "duration": 20,
    "start_time": "2022-03-12T10:10:47.807Z"
   },
   {
    "duration": 13,
    "start_time": "2022-03-12T10:10:47.828Z"
   },
   {
    "duration": 9,
    "start_time": "2022-03-12T10:10:47.842Z"
   },
   {
    "duration": 10438,
    "start_time": "2022-03-12T10:10:47.853Z"
   },
   {
    "duration": 63881,
    "start_time": "2022-03-12T10:10:58.293Z"
   },
   {
    "duration": 46335,
    "start_time": "2022-03-12T10:12:02.175Z"
   },
   {
    "duration": 6,
    "start_time": "2022-03-12T10:12:48.512Z"
   },
   {
    "duration": 10811,
    "start_time": "2022-03-12T10:12:48.605Z"
   },
   {
    "duration": 4,
    "start_time": "2022-03-12T10:12:59.418Z"
   },
   {
    "duration": 6,
    "start_time": "2022-03-12T10:12:59.424Z"
   },
   {
    "duration": 16,
    "start_time": "2022-03-12T10:12:59.431Z"
   },
   {
    "duration": 65689,
    "start_time": "2022-03-12T10:12:59.449Z"
   },
   {
    "duration": 10580,
    "start_time": "2022-03-12T10:14:05.139Z"
   },
   {
    "duration": 141254,
    "start_time": "2022-03-12T10:14:15.720Z"
   },
   {
    "duration": 199,
    "start_time": "2022-03-12T10:16:36.976Z"
   },
   {
    "duration": 568,
    "start_time": "2022-03-12T10:16:37.177Z"
   },
   {
    "duration": 38,
    "start_time": "2022-03-12T10:26:59.528Z"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Содержание",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "174.391px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
